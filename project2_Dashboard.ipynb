{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichieGarafola/Project2_Housing_Price_Sentiment_Advisor/blob/main/project2_Dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de54a40f",
      "metadata": {
        "id": "de54a40f"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a5873d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5873d4",
        "outputId": "f48820a7-998b-4a57-c7f3-78b636ce6376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (0.20.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: newsapi-python in /usr/local/lib/python3.7/dist-packages (0.2.6)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from newsapi-python) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hvplot in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: colorcet>=2 in /usr/local/lib/python3.7/dist-packages (from hvplot) (3.0.0)\n",
            "Requirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hvplot) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from hvplot) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hvplot) (21.3)\n",
            "Requirement already satisfied: holoviews>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hvplot) (1.14.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from hvplot) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->hvplot) (4.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->hvplot) (2.11.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->hvplot) (5.1.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->hvplot) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->hvplot) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->hvplot) (3.13)\n",
            "Requirement already satisfied: param>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from colorcet>=2->hvplot) (1.12.1)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from colorcet>=2->hvplot) (0.4.8)\n",
            "Requirement already satisfied: panel>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from holoviews>=1.11.0->hvplot) (0.12.1)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from holoviews>=1.11.0->hvplot) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->hvplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hvplot) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->hvplot) (2022.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (4.64.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (3.3.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=1.0.0->hvplot) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->panel>=0.8.0->holoviews>=1.11.0->hvplot) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->panel>=0.8.0->holoviews>=1.11.0->hvplot) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->panel>=0.8.0->holoviews>=1.11.0->hvplot) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.7/dist-packages (1.14.9)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.7/dist-packages (from holoviews) (3.0.0)\n",
            "Requirement already satisfied: param<2.0,>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from holoviews) (1.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from holoviews) (21.3)\n",
            "Requirement already satisfied: panel>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from holoviews) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from holoviews) (1.21.6)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from holoviews) (2.2.0)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from holoviews) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->holoviews) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->holoviews) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews) (2.23.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews) (3.3.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews) (5.0.0)\n",
            "Requirement already satisfied: bokeh<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews) (2.3.3)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel>=0.8.0->holoviews) (4.1.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel>=0.8.0->holoviews) (5.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel>=0.8.0->holoviews) (2.11.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel>=0.8.0->holoviews) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel>=0.8.0->holoviews) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh<2.4.0,>=2.3.0->panel>=0.8.0->holoviews) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->holoviews) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.20.0->holoviews) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->panel>=0.8.0->holoviews) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->panel>=0.8.0->holoviews) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->panel>=0.8.0->holoviews) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "# Installs\n",
        "\n",
        "# Hide Env \n",
        "!pip install python-dotenv\n",
        "\n",
        "# News API\n",
        "!pip install newsapi-python\n",
        "\n",
        "# Social Media Scraper\n",
        "!pip install snscrape\n",
        "\n",
        "# Visualization Tools\n",
        "!pip install hvplot\n",
        "!pip install holoviews"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdab66cf",
      "metadata": {
        "id": "fdab66cf"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5500a81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "c5500a81",
        "outputId": "9564b4b3-62dd-4010-ad8a-3bc6a6d17af5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "    if (js_modules == null) js_modules = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    var skip = [];\n",
              "    if (window.requirejs) {\n",
              "      window.requirejs.config({'packages': {}, 'paths': {'plotly': 'https://cdn.plot.ly/plotly-latest.min'}, 'shim': {}});\n",
              "      \n",
              "      require([\"plotly\"], function(Plotly) {\n",
              "\twindow.Plotly = Plotly\n",
              "      })\n",
              "      \n",
              "    }\n",
              "    if (((window['Plotly'] !== undefined) && (!(window['Plotly'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.plot.ly/plotly-latest.min.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (var i = 0; i < js_modules.length; i++) {\n",
              "      var url = js_modules[i];\n",
              "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    if (!js_urls.length && !js_modules.length) {\n",
              "      on_load()\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  var js_urls = [\"https://code.jquery.com/jquery-3.4.1.min.js\", \"https://cdn.plot.ly/plotly-latest.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/panel.min.js\"];\n",
              "  var js_modules = [];\n",
              "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/widgets.css\"];\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {} // ensure no trailing comma for IE\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    }\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, js_modules, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'plotly': 'https://cdn.plot.ly/plotly-latest.min'}, 'shim': {}});\n      \n      require([\"plotly\"], function(Plotly) {\n\twindow.Plotly = Plotly\n      })\n      \n    }\n    if (((window['Plotly'] !== undefined) && (!(window['Plotly'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.plot.ly/plotly-latest.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://code.jquery.com/jquery-3.4.1.min.js\", \"https://cdn.plot.ly/plotly-latest.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/javascript": [
              "\n",
              "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
              "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
              "}\n",
              "\n",
              "\n",
              "    function JupyterCommManager() {\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
              "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        comm_manager.register_target(comm_id, function(comm) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        });\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        });\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
              "          var messages = comm.messages[Symbol.asyncIterator]();\n",
              "          function processIteratorResult(result) {\n",
              "            var message = result.value;\n",
              "            console.log(message)\n",
              "            var content = {data: message.data, comm_id};\n",
              "            var buffers = []\n",
              "            for (var buffer of message.buffers || []) {\n",
              "              buffers.push(new DataView(buffer))\n",
              "            }\n",
              "            var metadata = message.metadata || {};\n",
              "            var msg = {content, buffers, metadata}\n",
              "            msg_handler(msg);\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "          return messages.next().then(processIteratorResult);\n",
              "        })\n",
              "      }\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
              "      if (comm_id in window.PyViz.comms) {\n",
              "        return window.PyViz.comms[comm_id];\n",
              "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
              "        if (msg_handler) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        }\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
              "        comm.open();\n",
              "        if (msg_handler) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        }\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
              "        comm_promise.then((comm) => {\n",
              "          window.PyViz.comms[comm_id] = comm;\n",
              "          if (msg_handler) {\n",
              "            var messages = comm.messages[Symbol.asyncIterator]();\n",
              "            function processIteratorResult(result) {\n",
              "              var message = result.value;\n",
              "              var content = {data: message.data};\n",
              "              var metadata = message.metadata || {comm_id};\n",
              "              var msg = {content, metadata}\n",
              "              msg_handler(msg);\n",
              "              return messages.next().then(processIteratorResult);\n",
              "            }\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "        }) \n",
              "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
              "          return comm_promise.then((comm) => {\n",
              "            comm.send(data, metadata, buffers, disposeOnDone);\n",
              "          });\n",
              "        };\n",
              "        var comm = {\n",
              "          send: sendClosure\n",
              "        };\n",
              "      }\n",
              "      window.PyViz.comms[comm_id] = comm;\n",
              "      return comm;\n",
              "    }\n",
              "    window.PyViz.comm_manager = new JupyterCommManager();\n",
              "    \n",
              "\n",
              "\n",
              "var JS_MIME_TYPE = 'application/javascript';\n",
              "var HTML_MIME_TYPE = 'text/html';\n",
              "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
              "var CLASS_NAME = 'output';\n",
              "\n",
              "/**\n",
              " * Render data to the DOM node\n",
              " */\n",
              "function render(props, node) {\n",
              "  var div = document.createElement(\"div\");\n",
              "  var script = document.createElement(\"script\");\n",
              "  node.appendChild(div);\n",
              "  node.appendChild(script);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when a new output is added\n",
              " */\n",
              "function handle_add_output(event, handle) {\n",
              "  var output_area = handle.output_area;\n",
              "  var output = handle.output;\n",
              "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "    return\n",
              "  }\n",
              "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "  if (id !== undefined) {\n",
              "    var nchildren = toinsert.length;\n",
              "    var html_node = toinsert[nchildren-1].children[0];\n",
              "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var scripts = [];\n",
              "    var nodelist = html_node.querySelectorAll(\"script\");\n",
              "    for (var i in nodelist) {\n",
              "      if (nodelist.hasOwnProperty(i)) {\n",
              "        scripts.push(nodelist[i])\n",
              "      }\n",
              "    }\n",
              "\n",
              "    scripts.forEach( function (oldScript) {\n",
              "      var newScript = document.createElement(\"script\");\n",
              "      var attrs = [];\n",
              "      var nodemap = oldScript.attributes;\n",
              "      for (var j in nodemap) {\n",
              "        if (nodemap.hasOwnProperty(j)) {\n",
              "          attrs.push(nodemap[j])\n",
              "        }\n",
              "      }\n",
              "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
              "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
              "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
              "    });\n",
              "    if (JS_MIME_TYPE in output.data) {\n",
              "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
              "    }\n",
              "    output_area._hv_plot_id = id;\n",
              "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
              "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
              "    } else {\n",
              "      window.PyViz.plot_index[id] = null;\n",
              "    }\n",
              "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "    var bk_div = document.createElement(\"div\");\n",
              "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var script_attrs = bk_div.children[0].attributes;\n",
              "    for (var i = 0; i < script_attrs.length; i++) {\n",
              "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "    }\n",
              "    // store reference to server id on output_area\n",
              "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when an output is cleared or removed\n",
              " */\n",
              "function handle_clear_output(event, handle) {\n",
              "  var id = handle.cell.output_area._hv_plot_id;\n",
              "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
              "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
              "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
              "  if (server_id !== null) {\n",
              "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
              "    return;\n",
              "  } else if (comm !== null) {\n",
              "    comm.send({event_type: 'delete', 'id': id});\n",
              "  }\n",
              "  delete PyViz.plot_index[id];\n",
              "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
              "    var doc = window.Bokeh.index[id].model.document\n",
              "    doc.clear();\n",
              "    const i = window.Bokeh.documents.indexOf(doc);\n",
              "    if (i > -1) {\n",
              "      window.Bokeh.documents.splice(i, 1);\n",
              "    }\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle kernel restart event\n",
              " */\n",
              "function handle_kernel_cleanup(event, handle) {\n",
              "  delete PyViz.comms[\"hv-extension-comm\"];\n",
              "  window.PyViz.plot_index = {}\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle update_display_data messages\n",
              " */\n",
              "function handle_update_output(event, handle) {\n",
              "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
              "  handle_add_output(event, handle)\n",
              "}\n",
              "\n",
              "function register_renderer(events, OutputArea) {\n",
              "  function append_mime(data, metadata, element) {\n",
              "    // create a DOM node to render to\n",
              "    var toinsert = this.create_output_subarea(\n",
              "    metadata,\n",
              "    CLASS_NAME,\n",
              "    EXEC_MIME_TYPE\n",
              "    );\n",
              "    this.keyboard_manager.register_events(toinsert);\n",
              "    // Render to node\n",
              "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "    render(props, toinsert[0]);\n",
              "    element.append(toinsert);\n",
              "    return toinsert\n",
              "  }\n",
              "\n",
              "  events.on('output_added.OutputArea', handle_add_output);\n",
              "  events.on('output_updated.OutputArea', handle_update_output);\n",
              "  events.on('clear_output.CodeCell', handle_clear_output);\n",
              "  events.on('delete.Cell', handle_clear_output);\n",
              "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
              "\n",
              "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "    safe: true,\n",
              "    index: 0\n",
              "  });\n",
              "}\n",
              "\n",
              "if (window.Jupyter !== undefined) {\n",
              "  try {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  } catch(err) {\n",
              "  }\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Initialize imports\n",
        "import panel as pn\n",
        "pn.extension('plotly')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "import matplotlib as mpl\n",
        "\n",
        "# ENV file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Apis for our Data\n",
        "import pandas_datareader as pdr\n",
        "from pandas_datareader import data as wb\n",
        "\n",
        "# Date time format\n",
        "import datetime as dt\n",
        "from pandas.tseries.offsets import DateOffset\n",
        "\n",
        "# Machine Learning Libraries \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pandas.tseries.offsets import DateOffset\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import tree\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "#NLP\n",
        "import nltk as nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "from nltk import ngrams\n",
        "from string import punctuation\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from newsapi.newsapi_client import NewsApiClient\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "mpl.rcParams['figure.figsize'] = [20.0, 10.0]\n",
        "\n",
        "# Twitter Scraper\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "\n",
        "# Visualization\n",
        "\n",
        "import hvplot.pandas\n",
        "import holoviews as hv\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "pd.options.plotting.backend = 'plotly'\n",
        "\n",
        "# Prophet\n",
        "from fbprophet import Prophet\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Set `bokeh` to render hvPlot charts\n",
        "hv.extension(\"bokeh\")\n",
        "\n",
        "# Load hidden enviornment\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e3384a",
      "metadata": {
        "id": "f5e3384a"
      },
      "outputs": [],
      "source": [
        "# Dictionary of States to be used for home prices \n",
        "\n",
        "# User Inputs State\n",
        "# Dictionary for home prices\n",
        "# CA= LA, FL= Tampa, WA= washington, DC = washington DC\n",
        "# Creating a Dictionary\n",
        "Dict = {'CA': 'LXXRSA',\n",
        "        'WA': 'SEXRNSA',\n",
        "        'NY': 'NYXRSA',\n",
        "        'IL': 'CHXRSA',\n",
        "        'AZ': 'PHXRNSA',\n",
        "        'FL': 'TPXRSA',\n",
        "        'TX': 'DAXRNSA',\n",
        "        'CO': 'DNXRSA',\n",
        "        'MA': 'BOXRSA',\n",
        "        'GA': 'ATXRNSA',\n",
        "        'OR': 'POXRSA',\n",
        "        'NV': 'LVXRNSA',\n",
        "        'DC': 'WDXRSA',\n",
        "        'USA': 'CSUSHPINSA'}\n",
        "\n",
        "# States Housing Prices\n",
        "# Initiate the desired State\n",
        "name=str(input('Enter State abbreviation ')).upper()\n",
        "ticker=(Dict.get(name))\n",
        "start = dt.datetime(1987, 1, 1)\n",
        "end = dt.datetime(2023, 1, 27)\n",
        "states_housing_prices = wb.DataReader(f'{ticker}', 'fred', start, end)\n",
        "name_2=(Dict.get(f'{name}'))\n",
        "# resample data - convert monthly data to daily data by forward filling the missing data\n",
        "states_housing_prices = states_housing_prices[[f'{name_2}']].resample(\"D\").ffill()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b9aba63",
      "metadata": {
        "id": "6b9aba63"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013ff778",
      "metadata": {
        "id": "013ff778"
      },
      "outputs": [],
      "source": [
        "# Inputed state\n",
        "states_housing_prices_plot = states_housing_prices.plot(title = f\"{name} 'State Home Prices'\");\n",
        "min_states_housing_prices = states_housing_prices.min()\n",
        "max_states_housing_prices = states_housing_prices.max()\n",
        "# USA\n",
        "USA = wb.DataReader('CSUSHPINSA', 'fred', start, end)\n",
        "USA = USA.resample(\"D\").ffill()\n",
        "usa_plot = USA.plot(title = \"United State National Home Price\");\n",
        "min_USA = USA[['CSUSHPINSA']].min()\n",
        "max_USA = USA[['CSUSHPINSA']].max()\n",
        "# Mortgage Rates\n",
        "mortgage15_year = wb.DataReader('MORTGAGE15US', 'fred', start, end)\n",
        "mortgage15_year = mortgage15_year['MORTGAGE15US'].resample(\"D\").ffill()\n",
        "mortgage30_year = wb.DataReader('MORTGAGE30US', 'fred',  start, end )\n",
        "mortgage30_year = mortgage30_year['MORTGAGE30US'].resample(\"D\").ffill()\n",
        "mortgage_combined = pd.concat([mortgage15_year, mortgage30_year], axis=1, join=\"inner\")\n",
        "mortgage_combined_plot = mortgage_combined.plot(title = \"15 Year Rates vs 30 Year Rates\", xlabel = \"Dates\", ylabel = \"Annual Percetnage\", figsize=(20,10))\n",
        "#\n",
        "states_vs_USA = pd.concat([states_housing_prices, USA], axis=1, join=\"inner\")\n",
        "states_vs_USA.plot(title = \"State Home Price vs United States Average\", figsize=(20,10))\n",
        "#\n",
        "housing_prices = pd.concat([USA, states_housing_prices], axis=1, join=\"inner\")\n",
        "housing_prices.columns=[\"USA Housing Prices |\",f\"{name} Housing Price\"]\n",
        "# # Join all states, and the us national housing index into a single DataFrame with columns identifying each states prices.\n",
        "all_states =  wb.DataReader(['LXXRSA', 'SEXRNSA', 'NYXRSA', 'CHXRSA', 'PHXRSA', 'TPXRSA', 'DNXRSA', 'BOXRSA', 'ATXRNSA', 'POXRSA', 'LVXRNSA', 'WDXRSA', 'CSUSHPINSA'], 'fred', start, end)\n",
        "all_states.columns = ['CA', 'WA', 'NY', 'IL', 'AZ', 'FL', 'CO', 'MA', 'GA', 'OR', 'NV', 'DC', 'USA']\n",
        "all_states = all_states.resample(\"D\").ffill()\n",
        "all_states.plot(figsize=(30,10), title= \"All States Prices\", xlabel= \"Year\", ylabel= \"Price\", fontsize= 20);\n",
        "# Calculate the daily standard deviations of all states housing prices \n",
        "all_states_std = all_states.std()\n",
        "all_states_std = pd.DataFrame(all_states_std)\n",
        "all_states_std.columns=({\"Standard Deviation\"})\n",
        "# Determine which states housing prices are more Expensive than the U.S. National Home Price Index\n",
        "isolated_USA = all_states[\"USA\"].std()\n",
        "risk = all_states_std > isolated_USA\n",
        "risk = pd.DataFrame(risk)\n",
        "risk.columns=({\"More Expensive than the U.S. National Home Price Index\"})\n",
        "# Calculate and plot rolling std for all portfolios with 21-day window\n",
        "portfolio_21_day_std = all_states.rolling(window = 21).std()\n",
        "portfolio_21_day_std = portfolio_21_day_std.plot(figsize=(20, 10));\n",
        "# correlation\n",
        "correlation = all_states.corr()\n",
        "correlation_plot = sns.heatmap(correlation, vmin=-1, vmax=1);\n",
        "# Beta\n",
        "covariance = all_states[f'{name}'].cov(all_states['USA'])\n",
        "variance = all_states['USA'].var()\n",
        "beta = covariance / variance\n",
        "beta_plot = sns.lmplot(x = \"USA\", y = f\"{name}\", data = all_states, aspect = 1.5, fit_reg = True);\n",
        "# API\n",
        "api_key = os.getenv('newsapi')\n",
        "# newsapi= NewsApiClient(api_key=os.environ[\"newsapi\"])\n",
        "# sentiment = newsapi.get_everything(q=\"housing crisis\", sort_by=\"relevancy\", language = \"en\",page_size=100,)\n",
        "# #\n",
        "# # NLP\n",
        "# # Create the economic reports sentiment scores DataFrame\n",
        "# housing_sentiments = []\n",
        "# for article in sentiment[\"articles\"]:\n",
        "#     try:\n",
        "#         text = article[\"content\"]\n",
        "#         date = article[\"publishedAt\"][:10]\n",
        "#         sentiment = analyzer.polarity_scores(text)\n",
        "#         compound = sentiment[\"compound\"]\n",
        "#         pos = sentiment[\"pos\"]\n",
        "#         neu = sentiment[\"neu\"]\n",
        "#         neg = sentiment[\"neg\"]\n",
        "        \n",
        "#         housing_sentiments.append({\n",
        "#             \"text\": text,\n",
        "#             \"date\": date,\n",
        "#             \"compound\": compound,\n",
        "#             \"positive\": pos,\n",
        "#             \"negative\": neg,\n",
        "#             \"neutral\": neu\n",
        "#         })\n",
        "        \n",
        "#     except AttributeError:\n",
        "#         pass    \n",
        "# housing_report_df = pd.DataFrame(housing_sentiments)\n",
        "# #\n",
        "# describe_housing_report_df = housing_report_df.describe()\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# sw = set(stopwords.words('english'))\n",
        "# #\n",
        "# housing_report_df['tokens'] = housing_report_df['text'].apply(word_tokenize)\n",
        "# #\n",
        "# housing_sentiment_ngrams = ngrams(\n",
        "#     tokenizer(' '.join(housing_report_df['text'])),\n",
        "#     n=2,)\n",
        "# # \n",
        "# wc_housing_sentiment = WordCloud().generate(\n",
        "#     ' '.join(tokenizer(\n",
        "#         ' '.join(housing_report_df['text']))\n",
        "#     ))\n",
        "#\n",
        "# Twitter sentiment Analysis\n",
        "# Get user input\n",
        "query = input(\"Query: \")\n",
        "# As long as the query is valid (not empty or equal to '#')...\n",
        "if query != '':\n",
        "    number_of_tweets = input(\"Enter the number of tweets you want to Analyze: \")\n",
        "    if number_of_tweets != '' :\n",
        "        number_of_days = input(\"Enter the number of days you want to Scrape Twitter for: \")\n",
        "        if number_of_days != '':\n",
        "                #Creating list to append tweet data\n",
        "                tweets_list = []\n",
        "                now = dt.date.today()\n",
        "                now = now.strftime('%Y-%m-%d')\n",
        "                yesterday = dt.date.today() - dt.timedelta(days = int(number_of_days))\n",
        "                yesterday = yesterday.strftime('%Y-%m-%d')\n",
        "                for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query + ' lang:en since:' +  yesterday + ' until:' + now + ' -filter:links -filter:replies').get_items()):\n",
        "                    if i > int(number_of_tweets):\n",
        "                        break\n",
        "                    tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
        "                # Creating a dataframe from the tweets list above \n",
        "                df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
        "# Create a function to clean the tweets\n",
        "def cleanTxt(text):\n",
        "    text = re.sub('@[A-Za-z0–9]+', '', text) #Removes @mentions\n",
        "    text = re.sub('#', '', text) # Removes '#' hash tag\n",
        "    text = re.sub('RT[\\s]+', '', text) # Removes RT\n",
        "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removes hyperlink\n",
        "    return text\n",
        "df[\"Text\"] = df[\"Text\"].apply(cleanTxt)\n",
        "\n",
        "# Sentiment Analysis\n",
        "def percentage(part,whole):\n",
        "    return 100 * float(part)/float(whole)\n",
        "#\n",
        "# Assigning Initial Values\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "sentiment = 0\n",
        "# Creating empty lists\n",
        "tweet_list1 = []\n",
        "neutral_list = []\n",
        "negative_list = []\n",
        "positive_list = []\n",
        "sentiment_list = []\n",
        "# Iterating over the tweets in the dataframe\n",
        "for tweet in df['Text']:\n",
        "    tweet_list1.append(tweet)\n",
        "    analyzer = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
        "    neg = analyzer['neg']\n",
        "    neu = analyzer['neu']\n",
        "    pos = analyzer['pos']\n",
        "    comp = analyzer['compound']\n",
        "\n",
        "    if neg > pos:\n",
        "        negative_list.append(tweet) \n",
        "        negative += 1 \n",
        "        sentiment_list.append(-1) \n",
        "        sentiment += 1\n",
        "    elif pos > neg:\n",
        "        positive_list.append(tweet) \n",
        "        positive += 1 \n",
        "        sentiment_list.append(1) \n",
        "        sentiment += 1\n",
        "    elif pos == neg:\n",
        "        neutral_list.append(tweet) \n",
        "        neutral += 1  \n",
        "\n",
        "positive = percentage(positive, len(df)) \n",
        "negative = percentage(negative, len(df))\n",
        "neutral = percentage(neutral, len(df))  \n",
        "tweet_list1 = pd.DataFrame(tweet_list1)\n",
        "neutral_list = pd.DataFrame(neutral_list)\n",
        "negative_list = pd.DataFrame(negative_list)\n",
        "positive_list = pd.DataFrame(positive_list)\n",
        "sentiment_list = pd.DataFrame(sentiment_list)\n",
        "#\n",
        "sentiment_list = pd.DataFrame(sentiment_list)\n",
        "sentiment_list.columns=['sentiment']\n",
        "tweet_list1 = pd.DataFrame(tweet_list1)\n",
        "tweet_list1.columns=['tweet']\n",
        "twitter_dataframe = pd.concat([sentiment_list, tweet_list1 ] , axis=1, join=\"inner\")\n",
        "# \n",
        "stop_words = set(stopwords.words('english'))\n",
        "# \n",
        "# Machine learning on NLP\n",
        "def preprocess_tweet_text(tweet):\n",
        "\n",
        "    tweet.lower()\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    tweet_tokens = word_tokenize(tweet)\n",
        "    filtered_words = [w for w in tweet_tokens if not w in stop_words]\n",
        "    ps = PorterStemmer()\n",
        "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
        "    return \" \".join(filtered_words)\n",
        "def get_feature_vector(train_fit):\n",
        "    vector = TfidfVectorizer(sublinear_tf=True)\n",
        "    vector.fit(train_fit)\n",
        "    return vector\n",
        "\n",
        "def int_to_string(sentiment):\n",
        "    if sentiment == 0:\n",
        "        return \"Negative\"\n",
        "    elif sentiment == 2:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\"\n",
        "\n",
        "twitter_dataframe.tweet = twitter_dataframe['tweet'].apply(preprocess_tweet_text)\n",
        "tf_vector = get_feature_vector(np.array(twitter_dataframe.iloc[:, 1]).ravel())\n",
        "X = tf_vector.transform(np.array(twitter_dataframe.iloc[:, 1]).ravel())\n",
        "y = np.array(twitter_dataframe.iloc[:, 0]).ravel()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=58)\n",
        "ComplementNB_model = ComplementNB() #  ComplementNB Model\n",
        "ComplementNB_model.fit(X_train, y_train) # Fit\n",
        "y_predict_ComplementNB = ComplementNB_model.predict(X_test) # Predict\n",
        "#\n",
        "MultinomialNB_model = MultinomialNB() #  MultinomialNB Model\n",
        "MultinomialNB_model.fit(X_train, y_train) # Fit\n",
        "y_predict_MultinomialNB = MultinomialNB_model.predict(X_test) # Predict\n",
        "#\n",
        "LogR_model = LogisticRegression(solver='lbfgs') # Model \n",
        "LogR_model.fit(X_train, y_train) # Fit\n",
        "y_predict_log = LogR_model.predict(X_test) # Predict\n",
        "#\n",
        "train_data, test_data = train_test_split(twitter_dataframe, test_size=0.2,random_state=58) # adjust test size and random state to increase the accuracy\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data.tweet)\n",
        "word_index = tokenizer.word_index\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet),maxlen = 50)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet),maxlen = 50)\n",
        "#\n",
        "# Time Series\n",
        "# Prophet\n",
        "model_mortgage15 = Prophet()\n",
        "model_mortgage30 = Prophet()\n",
        "model_USA = Prophet()\n",
        "model_states_housing_prices = Prophet()\n",
        "mortgage15_year_prophet_model = mortgage15_year.reset_index()\n",
        "mortgage15_year_prophet_model.columns = ['ds', 'y']\n",
        "mortgage30_year_prophet_model = mortgage15_year.reset_index()\n",
        "mortgage30_year_prophet_model.columns = ['ds', 'y']\n",
        "states_housing_prices_prophet_model = states_housing_prices.reset_index()\n",
        "states_housing_prices_prophet_model.columns = ['ds', 'y']\n",
        "USA_prophet_model = USA.reset_index()\n",
        "USA_prophet_model.columns = ['ds', 'y']\n",
        "model_mortgage15.fit(mortgage15_year_prophet_model)\n",
        "model_mortgage30.fit(mortgage30_year_prophet_model)\n",
        "model_states_housing_prices.fit(states_housing_prices_prophet_model)\n",
        "model_USA.fit(USA_prophet_model)\n",
        "future_mortgage15 = model_mortgage15.make_future_dataframe(periods=52, freq=\"W\")\n",
        "future_mortgage30 = model_mortgage30.make_future_dataframe(periods=52, freq=\"W\")\n",
        "future_states_housing_prices = model_states_housing_prices.make_future_dataframe(periods=52, freq=\"W\")\n",
        "future_USA = model_USA.make_future_dataframe(periods=52, freq=\"W\")\n",
        "forecast_mortgage15 = model_mortgage15.predict(future_mortgage15)\n",
        "forecast_mortgage30 = model_mortgage30.predict(future_mortgage30)\n",
        "forecast_states_housing_prices = model_states_housing_prices.predict(future_states_housing_prices)\n",
        "forecast_USA = model_USA.predict(future_USA)\n",
        "forecast_mortgage15 = forecast_mortgage15.set_index('ds')\n",
        "forecast_mortgage30 = forecast_mortgage30.set_index('ds')\n",
        "forecast_states_housing_prices = forecast_states_housing_prices.set_index('ds')\n",
        "forecast_USA = forecast_USA.set_index('ds')\n",
        "#\n",
        "# Machine Learning Case Shiller state Index\n",
        "states_housing_prices_baseline = states_housing_prices\n",
        "states_housing_prices_baseline[\"Actual Closing Prices\"] = states_housing_prices_baseline[f'{name_2}'].pct_change()\n",
        "states_housing_prices_baseline = states_housing_prices_baseline.dropna()\n",
        "short_window = 5\n",
        "long_window = 13\n",
        "states_housing_prices_baseline['SMA_Fast'] = states_housing_prices_baseline[f'{name_2}'].rolling(window=short_window).mean()\n",
        "states_housing_prices_baseline['SMA_Slow'] = states_housing_prices_baseline[f'{name_2}'].rolling(window=long_window).mean()\n",
        "states_housing_prices_baseline = states_housing_prices_baseline.dropna()\n",
        "states_housing_prices_baseline['Signal'] = 0.0\n",
        "states_housing_prices_baseline.loc[(states_housing_prices_baseline['Actual Closing Prices'] >= 0), 'Signal'] = 1\n",
        "states_housing_prices_baseline.loc[(states_housing_prices_baseline['Actual Closing Prices'] < 0), 'Signal'] = -1\n",
        "states_housing_prices_baseline['Actual Closing Prices'] = states_housing_prices_baseline['Actual Closing Prices'] * states_housing_prices_baseline['Signal'].shift()\n",
        "#\n",
        "X = states_housing_prices_baseline[['SMA_Fast', 'SMA_Slow']]\n",
        "y = states_housing_prices_baseline['Signal']\n",
        "training_begin = X.index.min()\n",
        "training_end = X.index.min() + DateOffset(months=250)\n",
        "X_train = X.loc[training_begin:training_end]\n",
        "y_train = y.loc[training_begin:training_end]\n",
        "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
        "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
        "scaler = StandardScaler()\n",
        "X_scaler = scaler.fit(X_train)\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "svm_model = svm.SVC()\n",
        "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
        "svm_pred = svm_model.predict(X_test_scaled)\n",
        "svm_testing_report = classification_report(y_test, svm_pred)\n",
        "predictions_df = pd.DataFrame(index=X_test.index)\n",
        "predictions_df['Predicted'] = svm_pred\n",
        "predictions_df['Actual Returns'] = states_housing_prices_baseline[\"Actual Closing Prices\"]\n",
        "predictions_df['Strategy Returns'] = predictions_df[\"Actual Returns\"] * predictions_df[\"Predicted\"]\n",
        "cumulative_return_plot = (1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot();\n",
        "ada_model = AdaBoostClassifier()\n",
        "ada_model.fit(X_train_scaled,y_train)\n",
        "pred = ada_model.predict(X_test_scaled)\n",
        "ada_training_report = classification_report(y_test, pred)\n",
        "ada_pred_df = predictions_df.copy()\n",
        "ada_pred_df['Predicted'] = pred\n",
        "ada_pred_df['Strategy Returns'] = ada_pred_df[\"Actual Returns\"] * ada_pred_df[\"Predicted\"]\n",
        "#\n",
        "model_compare_df = pd.DataFrame(index=X_test.index)\n",
        "model_compare_df['Actual Returns'] = states_housing_prices_baseline[\"Actual Closing Prices\"]\n",
        "model_compare_df['SVM Strategy Returns'] = predictions_df[\"Actual Returns\"] * predictions_df[\"Predicted\"]\n",
        "model_compare_df['ADA Strategy Returns'] = ada_pred_df[\"Actual Returns\"] * ada_pred_df[\"Predicted\"]\n",
        "#\n",
        "decision_tree_model = tree.DecisionTreeClassifier()\n",
        "decision_tree_model.fit(X_train_scaled, y_train)\n",
        "pred = decision_tree_model.predict(X_test_scaled)\n",
        "lr_training_report = classification_report(y_test, pred)\n",
        "pred_df = predictions_df.copy()\n",
        "pred_df['Predicted'] = pred\n",
        "pred_df['Strategy Returns'] = pred_df[\"Actual Returns\"] * pred_df[\"Predicted\"]\n",
        "model_compare_df = pd.DataFrame(index=X_test.index)\n",
        "model_compare_df['Actual Returns'] = predictions_df['Actual Returns']\n",
        "model_compare_df['SVM Strategy Returns'] = predictions_df[\"Actual Returns\"] * predictions_df[\"Predicted\"]\n",
        "model_compare_df['Decision Tree Strategy Returns'] = pred_df[\"Actual Returns\"] * pred_df[\"Predicted\"]\n",
        "dot_data = tree.export_graphviz(decision_tree_model, out_file=None, feature_names=X.columns, class_names=[\"0\", \"1\"], filled=True)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "#\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "classifier = PassiveAggressiveClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "predictions = classifier.predict(X_test)\n",
        "predictions = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78b0ee9",
      "metadata": {
        "id": "c78b0ee9"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d5cb25",
      "metadata": {
        "id": "83d5cb25"
      },
      "outputs": [],
      "source": [
        "def inputed_state_housing_price_plot():\n",
        "    # Plot the state index of the users desire\n",
        "    states_housing_prices_plot = states_housing_prices.drop(columns='Actual Closing Prices').hvplot.line(\n",
        "        xlabel= \"Date\", \n",
        "        ylabel = \"price\",\n",
        "        rot = 45,\n",
        "        title = f\"{name} 'State Home Prices'\",\n",
        "        color = \"dodgerblue\")\n",
        "    return states_housing_prices_plot\n",
        "\n",
        "def USA_index_plot():\n",
        "    # Plot the Case Shiller National United States Index\n",
        "    usa_plot = USA.hvplot.line(\n",
        "        xlabel= \"Date\", \n",
        "        ylabel = \"price\",\n",
        "        rot = 45,\n",
        "        title = \"United State National Home Price\",\n",
        "        color = \"red\")\n",
        "    return usa_plot\n",
        "\n",
        "def combined_mortgage_rates_plot():\n",
        "    # Plot the combined Mortgage data \n",
        "    mortgage_combined_plot = mortgage_combined.hvplot.line(\n",
        "        xlabel= \"Date\", \n",
        "        ylabel = \"Annual Percetnage\",\n",
        "        rot = 45,\n",
        "        title = \"15 Year Rates vs 30 Year Rates\")\n",
        "    return mortgage_combined_plot\n",
        "\n",
        "\n",
        "def states_vs_usa_plot():\n",
        "    # Plot The Desired States Housing prices vs the United States Average\n",
        "    housing_prices_plot = housing_prices.hvplot.line(\n",
        "        xlabel= \"Date\", \n",
        "        ylabel = \"Price\",\n",
        "        rot = 45,\n",
        "        title = \"State Home Price vs United States Average\")\n",
        "    return housing_prices_plot\n",
        "\n",
        "\n",
        "# Not sure if able to use this style on dashboard\n",
        "def linear_sequence_15year_plot():\n",
        "    \n",
        "    linear_sequence_15year = mortgage15_year\n",
        "    exponential_sequence = states_housing_prices\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(linear_sequence_15year, color='red')\n",
        "    ax.tick_params(axis='y', labelcolor='red')\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(exponential_sequence, color='green')\n",
        "    ax2.tick_params(axis='y', labelcolor='green')\n",
        "    plt.show()\n",
        "    return \n",
        "\n",
        "\n",
        "# Not sure if able to use this style on dashboard\n",
        "def linear_sequence_30year_plot():\n",
        "    linear_sequence_30year = mortgage30_year\n",
        "    exponential_sequence = states_housing_prices\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(linear_sequence_30year, color='blue')\n",
        "    ax.tick_params(axis='y', labelcolor='blue')\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(exponential_sequence, color='green')\n",
        "    ax2.tick_params(axis='y', labelcolor='green')\n",
        "    plt.show()\n",
        "    return \n",
        "\n",
        "\n",
        "def plot_all_states():\n",
        "    # Plot all States Housing prices to see leader and laggers\n",
        "    all_states_plot = all_states.hvplot.line(\n",
        "        xlabel= \"Date\", \n",
        "        ylabel = \"Price\",\n",
        "        rot = 45,\n",
        "        title = \"All States Prices\")\n",
        "    return all_states_plot\n",
        "\n",
        "\n",
        "def plot_portfolio_21_day_std():\n",
        "    portfolio_21_day_std_plot = portfolio_21_day_std.plot(\n",
        "        xlabel= \"Date\", \n",
        "        ylabel = \"STD\",\n",
        "        rot = 45,\n",
        "        title = \"Rolling standard deviation for all states using a 21-day window\")\n",
        "    return portfolio_21_day_std_plot\n",
        "\n",
        "\n",
        "def all_states_correlation_plot(): \n",
        "    # Plot correlation plot for all States Housing prices \n",
        "    correlation_plot = sns.heatmap(\n",
        "        correlation, \n",
        "        vmin=-1, \n",
        "        vmax=1);\n",
        "    return correlation_plot\n",
        "\n",
        "def all_states_beta_plot(): \n",
        "# Plot beta trend\n",
        "# The closer the data points come to forming a straight line when plotted, the higher the correlation between the two variables, or the stronger the relationship. \n",
        "    beta_plot = sns.lmplot(\n",
        "        x = \"USA\", \n",
        "        y = f\"{name}\", \n",
        "        data = all_states, \n",
        "        aspect = 1.5,\n",
        "        fit_reg = True);\n",
        "    return beta_plot\n",
        "\n",
        "\n",
        "def tokenizer(text):\n",
        "    \"\"\"Tokenizes text.\"\"\"\n",
        "    # Remove the punctuation from text\n",
        "    # list(filter) so that we can have the list filter the punctuations.\n",
        "    words =  word_tokenize(text)\n",
        "    words = list(filter(lambda T:T not in punctuation, words))\n",
        "    words = list(filter(lambda T:T.lower(), words))\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    tokens = list(filter(lambda T:T.lower() not in sw, words))\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "def token_count(tokens, N=10):\n",
        "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
        "    return Counter(tokens).most_common(N)\n",
        "\n",
        "\n",
        "\n",
        "# Not sure if this will work.\n",
        "def word_cloud_for_newsapi():\n",
        "    wc_housing_sentiment = WordCloud().generate(\n",
        "    ' '.join(tokenizer(\n",
        "        ' '.join(housing_report_df['text']))))\n",
        "    plt.imshow(wc_housing_sentiment);\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "def cleanTxt(text):\n",
        "# Create a function to clean the tweets\n",
        "    text = re.sub('@[A-Za-z0–9]+', '', text) #Removes @mentions\n",
        "    text = re.sub('#', '', text) # Removes '#' hash tag\n",
        "    text = re.sub('RT[\\s]+', '', text) # Removes RT\n",
        "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removes hyperlink\n",
        "    return text\n",
        "df[\"Text\"] = df[\"Text\"].apply(cleanTxt)\n",
        "\n",
        "\n",
        "def percentage(part,whole):\n",
        "    # Sentiment Analysis\n",
        "    return 100 * float(part)/float(whole)\n",
        "\n",
        "# Not sure if this will work\n",
        "def twitter_sentiment_word_cloud():\n",
        "    # Create Pie Chart\n",
        "    labels = ['Positive ['+str(round(positive))+'%]' , 'Neutral ['+str(round(neutral))+'%]','Negative ['+str(round(negative))+'%]']\n",
        "    sizes = [positive, neutral, negative]\n",
        "    colors = ['yellowgreen', 'blue','red']\n",
        "    patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
        "    plt.style.use('default')\n",
        "    plt.legend(labels)\n",
        "    plt.title(\"Sentiment Analysis Result for keyword= \"+query+\"\" )\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "\n",
        "# Not sure if this will work\n",
        "def word_cloud(text):\n",
        "    # word cloud visualization\n",
        "    stopwords = set(STOPWORDS)\n",
        "    allWords = ' '.join([twts for twts in text])\n",
        "    wordCloud = WordCloud(background_color='black',width = 1600, height = 800,stopwords = stopwords,min_font_size = 20,max_font_size=150,colormap='prism').generate(allWords)\n",
        "    fig, ax = plt.subplots(figsize=(20,10), facecolor='k')\n",
        "    plt.imshow(wordCloud)\n",
        "    ax.axis(\"off\")\n",
        "    fig.tight_layout(pad=0)\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def preprocess_tweet_text(tweet):\n",
        "    # Process tweets, remove non a-z characters\n",
        "    tweet.lower()\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    tweet_tokens = word_tokenize(tweet)\n",
        "    filtered_words = [w for w in tweet_tokens if not w in stop_words]\n",
        "    ps = PorterStemmer()\n",
        "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "def get_feature_vector(train_fit):\n",
        "    vector = TfidfVectorizer(sublinear_tf=True)\n",
        "    vector.fit(train_fit)\n",
        "    return vector\n",
        "\n",
        "def int_to_string(sentiment):\n",
        "    if sentiment == 0:\n",
        "        return \"Negative\"\n",
        "    elif sentiment == 2:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\"\n",
        "    \n",
        "    \n",
        "def prophet_predictions_mortgage15():\n",
        "# Plot the Prophet predictions for mortgage15    \n",
        "    mortgage15_year_prophet_model = mortgage15_year.reset_index()\n",
        "    mortgage15_year_prophet_model.columns = ['ds', 'y']\n",
        "    forecast_mortgage15 = forecast_mortgage15.reset_index()\n",
        "    plot_model_mortgage15 = model_mortgage15.plot(forecast_mortgage15)\n",
        "    return plot_model_mortgage15\n",
        "\n",
        "\n",
        "def prophet_predictions_mortgage30():\n",
        "# Plot the Prophet predictions for mortgage30    \n",
        "    mortgage30_year_prophet_model = mortgage30_year.reset_index()\n",
        "    mortgage30_year_prophet_model.columns = ['ds', 'y']\n",
        "    forecast_mortgage30 = forecast_mortgage30.reset_index()\n",
        "    plot_model_mortgage30 = model_mortgage30.plot(forecast_mortgage30)\n",
        "    return plot_model_mortgage30\n",
        "    \n",
        "\n",
        "def prophet_predictions_inputted_state_index():\n",
        "# Plot the Prophet predictions for states_housing_prices\n",
        "    states_housing_prices_prophet_model = states_housing_prices.reset_index()\n",
        "    states_housing_prices_prophet_model.columns = ['ds', 'y']\n",
        "    forecast_states_housing_prices = forecasforecast_states_housing_pricest_mortgage15.reset_index()\n",
        "    plot_model_states_housing_prices = model_states_housing_prices.plot(forecast_states_housing_prices)\n",
        "    return plot_model_states_housing_prices\n",
        "\n",
        "def prophet_predictions_USA_index():\n",
        "# Plot the Prophet predictions for United States National Home Price Index\n",
        "    USA_prophet_model = USA.reset_index()\n",
        "    USA_prophet_model.columns = ['ds', 'y']\n",
        "    forecast_USA = forecast_USA.reset_index()\n",
        "    plot_model_USA = model_USA.plot(forecast_USA)\n",
        "    return plot_model_USA\n",
        "\n",
        "def prophet_forecast_mortgage15():\n",
        "# Plot predictions for our forecast_mortgage15 DataFrame for the 52 week period \n",
        "    plot_forecast_mortgage15 = forecast_mortgage15[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-52:,:].plot()\n",
        "    return plot_forecast_mortgage15\n",
        "\n",
        "def prophet_forecast_mortgage30():\n",
        "# Plot predictions for our forecast_mortgage15 DataFrame for the 52 week period \n",
        "    plot_forecast_mortgage30 = forecast_mortgage30[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-52:,:].plot()\n",
        "    return plot_forecast_mortgage30\n",
        "\n",
        "def prophet_forecast_inputted_state_index():\n",
        "# Plot predictions for our forecast State Housing Prices DataFrame for the 52 week period \n",
        "    plot_forecast_states_housing_prices = forecast_states_housing_prices[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-52:,:].plot()\n",
        "    return plot_forecast_states_housing_prices\n",
        "\n",
        "def prophet_forecast_USA_index():\n",
        "# Plot predictions for our forecast United States National Home Price Index DataFrame for the 52 week period \n",
        "    plot_forecast_USA = forecast_USA[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-52:,:].plot()\n",
        "    return plot_forecast_USA\n",
        "\n",
        "\n",
        "def state_index_baseline():\n",
        "# Plot Actual Closing Prices to examine performance\n",
        "    plot_states_housing_prices_baseline = (1 + states_housing_prices_baseline['Actual Closing Prices']).cumprod().plot();\n",
        "    return plot_states_housing_prices_baseline\n",
        "\n",
        "\n",
        "def cumulative_returns():\n",
        "    # Plot the actual returns versus the strategy returns\n",
        "    cumulative_return_plot = (1 + predictions_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot();\n",
        "    return cumulative_return_plot\n",
        "\n",
        "def adaboostclassifier_plot():\n",
        "# Plot the actual returns versus the strategy returns\n",
        "    ada_pred_plot = (1 + ada_pred_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot();\n",
        "    return ada_pred_plot\n",
        "\n",
        "def adaboost_model_compare_plot():\n",
        "# Plot the actual returns versus the strategy returns\n",
        "    compare_models_plot = (1 + model_compare_df[[\"Actual Returns\", \"SVM Strategy Returns\",\"ADA Strategy Returns\"]]).cumprod().plot();\n",
        "    return compare_models_plot\n",
        "\n",
        "def decisiontreeclassifier_plot():\n",
        "    # Plot the actual returns versus the strategy returns\n",
        "    decisiontreeclassifier_vs_actual_plot = (1 + pred_df[[\"Actual Returns\", \"Strategy Returns\"]]).cumprod().plot();\n",
        "    return decisiontreeclassifier_vs_actual_plot\n",
        "\n",
        "\n",
        "def decisiontreeclassifier_model_compare_plot():\n",
        "    compare_models_decision_tree_plot = (1 + model_compare_df[[\"Actual Returns\", \"SVM Strategy Returns\",\"Decision Tree Strategy Returns\"]]).cumprod().plot();\n",
        "    return compare_models_decision_tree_plot\n",
        "\n",
        "def decisiontree():\n",
        "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e655dd",
      "metadata": {
        "id": "78e655dd"
      },
      "source": [
        "# Panel Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prophet_predictions_mortgage15():\n",
        "# Plot the Prophet predictions for mortgage15    \n",
        "    mortgage15_year_prophet_model = mortgage15_year.reset_index()\n",
        "    mortgage15_year_prophet_model.columns = ['ds', 'y']\n",
        "    test = forecast_mortgage15.reset_index()\n",
        "    plot_model_mortgage15 = model_mortgage15.plot(test)\n",
        "    return plot_model_mortgage15\n",
        "\n",
        "\n",
        "prophet_predictions_mortgage15()\n",
        "\n",
        "#mortgage15_year_panel = pn.Column('15yr Mortgage Rate', prophet_predictions_mortgage15()) #, prophet_forecast_mortgage15())"
      ],
      "metadata": {
        "id": "iiNRnSXCJzYF"
      },
      "id": "iiNRnSXCJzYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17548f0c",
      "metadata": {
        "id": "17548f0c"
      },
      "outputs": [],
      "source": [
        "# # Create a Title for the Dashboard\n",
        "# title = pn.pane.Markdown(\"\"\"\n",
        "#          'Housing Price Sentiment Advisor'\n",
        "#          \"\"\",\n",
        "#          width = 400)\n",
        "\n",
        "# welcome = pn.pane.Markdown('''\n",
        "#         This dashboard, created by Richie Garafola, Joseph Garcia and Marc Agnew presents a visual analysis of housing price sentiment based on the Case Shiller indices. \n",
        "#         You can navigate through the tabs above to explore more details about the evolution of state housing price index as it realtes to mortgage rates.\n",
        "#         ''')\n",
        "\n",
        "# mortgage15_year_panel = pn.Column('15yr Mortgage Rate',) ##add 15yr functions## )\n",
        "# mortgage30_year_panel = pn.Column('30yr Mortgage Rate',) ##add 30yr functions## )\n",
        "# desired_state_panel = pn.Column(f\"'{name}' State Index\",            )\n",
        "# USA_panel = pn.Column('Case-Shiller U.S. National Home Price Index',              )\n",
        "# summary_panel = pn.Column('Summary',                 )\n",
        "# conclusion_panel = pn.Column('Conclusion',)\n",
        "\n",
        "# Create a Title for the Dashboard\n",
        "title = pn.pane.Markdown(\"\"\"\n",
        "         'Housing Price Sentiment Advisor'\n",
        "         \"\"\",\n",
        "         width = 400)\n",
        "\n",
        "welcome = pn.pane.Markdown('''\n",
        "        This dashboard, created by Richie Garafola, Joseph Garcia and Marc Agnew presents a visual analysis of housing price sentiment based on the Case Shiller indices. \n",
        "        You can navigate through the tabs above to explore more details about the evolution of state housing price index as it realtes to mortgage rates.\n",
        "        ''')\n",
        "\n",
        "mortgage15_year_panel = pn.Column('15yr Mortgage Rate', linear_sequence_15year_plot(), prophet_predictions_mortgage15(), prophet_forecast_mortgage15())\n",
        "mortgage30_year_panel = pn.Column('30yr Mortgage Rate', linear_sequence_30year_plot(), prophet_predictions_mortgage30(), prophet_forecast_mortgage30())\n",
        "mortgage15_year_vs_30year_panel = pn.Column('15yr vs 30yr Mortgage Rate', combined_mortgage_rates_plot())\n",
        "desired_state_panel = pn.Column(f\"'{name}' State Index\", inputed_state_housing_price_plot(), prophet_predictions_inputted_state_index(), prophet_forecast_inputted_state_index())\n",
        "USA_panel = pn.Column('Case-Shiller U.S. National Home Price Index', USA_index_plot(), prophet_predictions_USA_index(), prophet_forecast_USA_index())\n",
        "desired_state_vs_USA_panel = pn.Column(f\"'{name}' State Index vs US National Index\", states_vs_usa_plot())\n",
        "all_states_panel = pn.Column('All States Index', all_states_plot(), portfolio_21_day_std_plot(), all_states_correlation_plot(), all_states_beta_plot())\n",
        "\n",
        "twitter_sentiment_panel = pn.Column('Twitter Sentiment', twitter_sentiment_word_cloud())\n",
        "machine_learning_panel = pn.Column('Machine Learning', state_index_baseline(), cumulative_returns(), adaboostclassifier_plot(), decisiontreeclassifier_plot(), decisiontreeclassifier_model_compare_plot(), decisiontree()) #  adaboost_model_compare_plot()\n",
        "summary_panel = pn.Column('Summary')\n",
        "conclusion_panel = pn.Column('Conclusion')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d913f55",
      "metadata": {
        "id": "0d913f55"
      },
      "source": [
        "**Tabs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5a89ca",
      "metadata": {
        "id": "1b5a89ca"
      },
      "outputs": [],
      "source": [
        "# tabs = pn.Tabs(\n",
        "#     (\"Welcome\", pn.Column(welcome)),\n",
        "#     (\"15yr Mortgage Rate\", mortgage15_year_panel),\n",
        "#     (\"30yr Mortgage Rate\", mortgage30_year_panel),\n",
        "#     (f\"'{name}' State Index\", desired_state_panel),\n",
        "#     (\"Case-Shiller U.S. National Home Price Index\", USA_panel),\n",
        "#     (\"Summary\", summary_panel),\n",
        "#     (\"Conclusion\", conclusion_panel),\n",
        "#     dynamic=True\n",
        "    \n",
        "# )   \n",
        "# tabs\n",
        "\n",
        "# ### Currency Conversion\n",
        "# dashboard = pn.Column(pn.Row(title),(tabs))\n",
        "\n",
        "tabs = pn.Tabs(\n",
        "    (\"Welcome\", pn.Column(welcome)),\n",
        "    (\"15yr Mortgage Rate\", mortgage15_year_panel),\n",
        "    (\"30yr Mortgage Rate\", mortgage30_year_panel),\n",
        "    (\"15yr vs 30yr Mortgage Rate\", mortgage15_year_vs_30year_panel),\n",
        "    (f\"'{name}' State Index\", desired_state_panel),\n",
        "    (\"Case-Shiller U.S. National Home Price Index\", USA_panel),\n",
        "    # (\"State Index vs US National Index\", desired_state_vs_USA_panel),\n",
        "    (\"All States Index\", all_states_panel),\n",
        "    (\"Twitter Sentiment\", twitter_sentiment_panel),\n",
        "    (\"Machine Learning\", machine_learning_panel),\n",
        "    (\"Summary\", summary_panel),\n",
        "    (\"Conclusion\", conclusion_panel),\n",
        "    dynamic=True\n",
        "    \n",
        ")   \n",
        "tabs\n",
        "\n",
        "### Currency Conversion\n",
        "#dashboard = pn.Column(pn.Row(title),(tabs))\n",
        "dashboard = pn.Column(pn.Row(title),tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44f4065",
      "metadata": {
        "id": "c44f4065"
      },
      "outputs": [],
      "source": [
        "dashboard.servable()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "449fc757",
      "metadata": {
        "id": "449fc757"
      },
      "source": [
        "# Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3f2768",
      "metadata": {
        "id": "1e3f2768"
      },
      "outputs": [],
      "source": [
        "inputed_state_housing_price_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db63746",
      "metadata": {
        "id": "2db63746"
      },
      "outputs": [],
      "source": [
        "USA_index_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce79e6ac",
      "metadata": {
        "id": "ce79e6ac"
      },
      "outputs": [],
      "source": [
        "combined_mortgage_rates_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca94ff57",
      "metadata": {
        "id": "ca94ff57"
      },
      "outputs": [],
      "source": [
        "states_vs_usa_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac104d3f",
      "metadata": {
        "id": "ac104d3f"
      },
      "outputs": [],
      "source": [
        "linear_sequence_15year_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "666632ae",
      "metadata": {
        "id": "666632ae"
      },
      "outputs": [],
      "source": [
        "linear_sequence_30year_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c685b88",
      "metadata": {
        "id": "0c685b88"
      },
      "outputs": [],
      "source": [
        "all_states_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8c0346",
      "metadata": {
        "id": "0e8c0346"
      },
      "outputs": [],
      "source": [
        "portfolio_21_day_std_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88884561",
      "metadata": {
        "id": "88884561"
      },
      "outputs": [],
      "source": [
        "all_states_correlation_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ade47bd",
      "metadata": {
        "id": "1ade47bd"
      },
      "outputs": [],
      "source": [
        "all_states_beta_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e1027c9",
      "metadata": {
        "id": "9e1027c9"
      },
      "outputs": [],
      "source": [
        "word_cloud_for_newsapi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d7c1e1",
      "metadata": {
        "id": "25d7c1e1"
      },
      "outputs": [],
      "source": [
        "# twitter_sentiment_word_cloud()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99dda712",
      "metadata": {
        "id": "99dda712"
      },
      "outputs": [],
      "source": [
        "# preprocess_tweet_text(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "802de538",
      "metadata": {
        "id": "802de538"
      },
      "outputs": [],
      "source": [
        "# int_to_string(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed51c82c",
      "metadata": {
        "id": "ed51c82c"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_mortgage15()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2505143",
      "metadata": {
        "id": "a2505143"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_mortgage30()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d60eef",
      "metadata": {
        "id": "32d60eef"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_inputted_state_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db3a948",
      "metadata": {
        "id": "2db3a948"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_USA_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f480742d",
      "metadata": {
        "id": "f480742d"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_mortgage15()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a35519",
      "metadata": {
        "id": "16a35519"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_mortgage30()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d9da8da",
      "metadata": {
        "id": "1d9da8da"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_inputted_state_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b5fe86",
      "metadata": {
        "id": "e8b5fe86"
      },
      "outputs": [],
      "source": [
        "prophet_predictions_USA_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a81071d",
      "metadata": {
        "id": "1a81071d"
      },
      "outputs": [],
      "source": [
        "state_index_baseline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f511267",
      "metadata": {
        "id": "8f511267"
      },
      "outputs": [],
      "source": [
        "cumulative_returns()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2516159",
      "metadata": {
        "id": "a2516159"
      },
      "outputs": [],
      "source": [
        "adaboostclassifier_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b5c7b2e",
      "metadata": {
        "id": "0b5c7b2e"
      },
      "outputs": [],
      "source": [
        "adaboost_model_compare_plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee8cce4",
      "metadata": {
        "id": "eee8cce4"
      },
      "outputs": [],
      "source": [
        "decisiontreeclassifier_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907c689b",
      "metadata": {
        "id": "907c689b"
      },
      "outputs": [],
      "source": [
        "decisiontreeclassifier_model_compare_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497cb1d4",
      "metadata": {
        "id": "497cb1d4"
      },
      "outputs": [],
      "source": [
        "decisiontree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331ed52c",
      "metadata": {
        "id": "331ed52c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "project2_Dashboard.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}